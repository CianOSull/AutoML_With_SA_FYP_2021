{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MainNotebook",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/CianOSull/AutoML_With_SA_FYP_2021/blob/H2O/MainNotebook.ipynb",
      "authorship_tag": "ABX9TyOEp7GDkxZxRxgLsiWz35rZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CianOSull/AutoML_With_SA_FYP_2021/blob/H2O/MainNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_zrt8fk5AJt"
      },
      "source": [
        "# Generic Notebook for running all the libraries\r\n",
        "\r\n",
        "How this notebook works is that it contains the code\r\n",
        "for loading and cleaning the dataset.\r\n",
        "\r\n",
        "Then there is multiple branches created on the\r\n",
        "Github that include the code for running each library.\r\n",
        "\r\n",
        "E.g. MLBox branch has the code for running MLBox."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJSxy1VR-mAM"
      },
      "source": [
        "# CURRENT BRANCH: H2O"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxc3argyH4PH"
      },
      "source": [
        "# Install Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wFpyMaK6tMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e639275e-451b-4a92-8d93-2437218f7f7f"
      },
      "source": [
        "# Insert any install comamnds in this cell\r\n",
        "!apt-get install default-jre\r\n",
        "!java -version\r\n",
        "!pip install h2o"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "default-jre is already the newest version (2:1.11-68ubuntu1~18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "Requirement already satisfied: h2o in /usr/local/lib/python3.6/dist-packages (3.32.0.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.7)\n",
            "Requirement already satisfied: colorama>=0.3.8 in /usr/local/lib/python3.6/dist-packages (from h2o) (0.4.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TNIZJ6c5hcF"
      },
      "source": [
        "# Preprocessing Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njEYGcZQ42t-"
      },
      "source": [
        "# Import the necessary modules for cleaning\r\n",
        "import math\r\n",
        "import time \r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.tokenize import word_tokenize \r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sPOCEGS5Xgn"
      },
      "source": [
        "# Create the set of stopwords for cleaning text\r\n",
        "stopwords = set(w.rstrip() for w in open('/content/drive/MyDrive/CIT/FYP/ImplementationFiles/stopwords.txt'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93NNPX-A5srS",
        "outputId": "93889702-e2b7-4951-b1c3-42927c92fbb7"
      },
      "source": [
        "# Download the necessary parts for the NLTK module\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4ptneBc5tAN"
      },
      "source": [
        "# This funciton handles celaning text\r\n",
        "def clean_text(text):\r\n",
        "    # Create the lemmatizer\r\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\r\n",
        "    \r\n",
        "    # Get rid of non alpha characters except \"'\" as it is needed for the lemment\r\n",
        "    text = \"\".join(c for c in text if c.isalnum() or c == \" \" or \"'\")\r\n",
        "    \r\n",
        "    # Get rid of capitals\r\n",
        "    text = text.lower()\r\n",
        "    \r\n",
        "    # Tokenize the words    \r\n",
        "    # Create tokens of each word\r\n",
        "    token_text = word_tokenize(text)\r\n",
        "    \r\n",
        "    # Get rid of any piece of text that isn't over 2 characters\r\n",
        "    token_text = [t for t in token_text if len(t) > 2] \r\n",
        "    \r\n",
        "    # Put words in base form by doing lemmatization\r\n",
        "    token_text = [wordnet_lemmatizer.lemmatize(t) for t in token_text]\r\n",
        "\r\n",
        "    # Remove stopwords\r\n",
        "    token_text = [t for t in token_text if t not in stopwords]\r\n",
        "    \r\n",
        "    # Return the tokens\r\n",
        "    return token_text"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu5dFDM75tjR"
      },
      "source": [
        "# This function will get the term frequencies for word in the review\r\n",
        "# TF = Term I frequency in document/total words in document\r\n",
        "def calc_tf(term_count, review_corpus):\r\n",
        "    # A dictionary of all the term frequencies found\r\n",
        "    tf_freq = dict.fromkeys(term_count.keys(), 0)   \r\n",
        "    \r\n",
        "    # Review corpus is a tokenized list so the total words iteh length\r\n",
        "    total_words = len(review_corpus)\r\n",
        "    \r\n",
        "    # Calculate the term frequency for each word\r\n",
        "    for word, count in term_count.items():\r\n",
        "        tf_freq[word] = count/total_words\r\n",
        "        \r\n",
        "    return tf_freq"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i64Bq0rH5uN0"
      },
      "source": [
        "# This calcualtes the idf\r\n",
        "# IDF = log(2)*(Total number of Documents/documents frequency or documents with term)\r\n",
        "def calc_idf(unique_terms, list_doc_terms):   \r\n",
        "    # A dicitonary of all the inverse document frequencies\r\n",
        "    idf = dict.fromkeys(unique_terms, 0)\r\n",
        "    \r\n",
        "    # Basically list_doc_terms has all the documents with the term count for each word\r\n",
        "    # You go through each document count the terms where they occured\r\n",
        "    for doc_terms in list_doc_terms:  \r\n",
        "        # This for loop is counting the amount of document a word was in\r\n",
        "        for word, value in doc_terms.items():\r\n",
        "            if 0 < value:\r\n",
        "                idf[word] += 1\r\n",
        "        \r\n",
        "    # Now we calculate idf\r\n",
        "    for word, value in idf.items():\r\n",
        "        idf[word] = math.log10(10 / float(value))\r\n",
        "    \r\n",
        "    return idf"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XTmL87F5uaU"
      },
      "source": [
        "# Modified this function to return a list as dictionaries arn't needed anymore\r\n",
        "def calc_tf_idf(tf, idf, n_terms):\r\n",
        "    # Create an array that is of length of the number of unique terms\r\n",
        "    tf_idf_array = np.zeros(n_terms)\r\n",
        "    \r\n",
        "    for index, (word, value) in enumerate(tf.items()):\r\n",
        "        # Add the tfidf to the array\r\n",
        "        tf_idf_array[index] = value*idf[word]\r\n",
        "    \r\n",
        "    return tf_idf_array"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzOme9px5uks"
      },
      "source": [
        "def process_text(text_data):\r\n",
        "    # A list of all the cleaned reviews\r\n",
        "    doc_list = []\r\n",
        "    \r\n",
        "    # List of all the unique terms\r\n",
        "    unique_terms = []\r\n",
        "    \r\n",
        "    # A list of all the term frequencies\r\n",
        "    tf_list = []\r\n",
        "    \r\n",
        "    for review in text_data:\r\n",
        "        # First clean the review\r\n",
        "        clean_review = clean_text(review)\r\n",
        "        \r\n",
        "        # Keeps track of the term counts for each word\r\n",
        "        count_dict = {}\r\n",
        "        \r\n",
        "        # Now lets find the total count for each word\r\n",
        "        for token in clean_review:\r\n",
        "            if token not in count_dict:\r\n",
        "                count_dict[token] = 1\r\n",
        "            else:\r\n",
        "                count_dict[token] += 1\r\n",
        "        \r\n",
        "        # Caclulate the term frequencies for each document\r\n",
        "        tf_list.append(calc_tf(count_dict, clean_review))\r\n",
        "        \r\n",
        "        # Then add the dictionary of counts for each document to the list\r\n",
        "        doc_list.append(count_dict)\r\n",
        "        \r\n",
        "        # Then add the new unique terms\r\n",
        "        unique_terms = set(unique_terms).union(set(clean_review))\r\n",
        "    \r\n",
        "    # Calculate the inverse document frequency value\r\n",
        "    idf = calc_idf(unique_terms, doc_list)\r\n",
        "    \r\n",
        "    # This array will contain the tfidf values for each term in each review\r\n",
        "    tfidf_values = np.zeros((len(tf_list), len(unique_terms)))\r\n",
        "    \r\n",
        "    # Now we can get the TFIDF for each document\r\n",
        "    for index, term_freq in enumerate(tf_list):\r\n",
        "        # This will return an array of the tfidf values calculated.\r\n",
        "        # The length of the unique terms list is passed in so that the \r\n",
        "        # Array that is returned matches the tfidf array\r\n",
        "        tf_idf_array = calc_tf_idf(term_freq, idf, len(unique_terms))\r\n",
        "        # Add this to the overall tfidf values calculated\r\n",
        "        tfidf_values[index,:] = tf_idf_array\r\n",
        "    \r\n",
        "    return tfidf_values"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUz1Vq_D6Ett"
      },
      "source": [
        "# Prepare the data\r\n",
        "def prepare_data():\r\n",
        "    print(\"=\"*50)\r\n",
        "\r\n",
        "    # Load the dataset\r\n",
        "    # imdb_df = pd.read_csv(\"IMDB Dataset.csv\")\r\n",
        "    imdb_df = pd.read_csv(\"/content/drive/MyDrive/CIT/FYP/ImplementationFiles/IMDB_Dataset.csv\")\r\n",
        "    print(\"Dataset loaded\")\r\n",
        "    print(\"=\"*50)\r\n",
        "\r\n",
        "    \r\n",
        "    # Change each positive and negative value to 1 and 0 respectively    \r\n",
        "    imdb_df['sentiment'] = imdb_df['sentiment'].map({'negative' : 0, 'positive' : 1})\r\n",
        "    \r\n",
        "    # For testing, a much smaller dataset is going to be used\r\n",
        "    imdb_df = imdb_df.head(5000)\r\n",
        "\r\n",
        "    # Group all the negative reviews and get the first 2500\r\n",
        "    imdb_df_neg = (imdb_df[imdb_df['sentiment'] == 0])[0:2500]\r\n",
        "    # Group all the positive and get the first 2500\r\n",
        "    imdb_df_pos = imdb_df[imdb_df['sentiment'] == 1]\r\n",
        "    \r\n",
        "    test_df = pd.concat([imdb_df_neg, imdb_df_pos]) \r\n",
        "    # print(test_df)\r\n",
        "    \r\n",
        "    # .values on a column of a dataframe returns a numpy array\r\n",
        "    # This is a numpy array of all the reviews\r\n",
        "    # initial_reviews = imdb_df['review'].values\r\n",
        "    initial_reviews = test_df['review'].values\r\n",
        "    \r\n",
        "    # This is a numpy array of all the positive and negativelabels\r\n",
        "    # labels = imdb_df['sentiment'].values\r\n",
        "    labels = test_df['sentiment'].values\r\n",
        "    \r\n",
        "    print(\"Creating Feature Vector\")\r\n",
        "    print(\"=\"*50)\r\n",
        "    start = time.time()\r\n",
        "    # Process the text data and create teh feature vector\r\n",
        "    feature_vector = process_text(initial_reviews)\r\n",
        "    end = time.time()\r\n",
        "    print(\"Feature Vector Created\")\r\n",
        "    print(f\"Execution time is {end - start} secs\")\r\n",
        "    print(\"=\"*50)\r\n",
        "    \r\n",
        "    # Shuffle the labesl and feature vector using sklearn shuffle\r\n",
        "    feature_vector, labels = shuffle(feature_vector, labels)\r\n",
        "    \r\n",
        "    # Creating train and test data\r\n",
        "    # The splits will be 80:20 \r\n",
        "    no_samples = 0.8\r\n",
        "    \r\n",
        "    # This gets the percentage of indexes from feature vector and uses those for training\r\n",
        "    X_train = feature_vector[0:int(no_samples*len(feature_vector))]\r\n",
        "    y_train = labels[0:int(no_samples*len(labels))]\r\n",
        "    \r\n",
        "    # Go from the index that was used for training to the final\r\n",
        "    X_test = feature_vector[int(no_samples*len(feature_vector)):len(feature_vector)]\r\n",
        "    y_test = labels[int(no_samples*len(labels)):len(labels)]\r\n",
        "\r\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew8tq1lj6v1L"
      },
      "source": [
        "# Create Model Section\r\n",
        "\r\n",
        "**Documentation on manipulating data for h2o**\r\n",
        "\r\n",
        "http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging.html\r\n",
        "\r\n",
        "http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html#automl-interface\r\n",
        "\r\n",
        "**BIG NOTE**\r\n",
        "\r\n",
        "It seems because of how much H2O automates everything, it only takes in files. Thus a possible solution for running it on the tf idf values is to make a pandas dataframe using the numpy values, then convert it to a csv file and then feed it into the h2o.\r\n",
        "\r\n",
        "There is also h2o.sklearn which allows h2o to work with sklearn and does allow it to work with numpy so maybe test that out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXNpEputu5yz",
        "outputId": "5eb7b618-5f0b-423d-ba62-6c8ede2d2f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "# Start up h2o\r\n",
        "import h2o\r\n",
        "h2o.init()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>1 min 50 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.32.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>17 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_6mmpwa</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.118 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O_API_Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.6.9 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         1 min 50 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.32.0.4\n",
              "H2O_cluster_version_age:    17 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_6mmpwa\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.118 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python_version:             3.6.9 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJwsjdtHvDw6",
        "outputId": "795ffa65-d30c-422c-df02-0728fd9a85ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load Dataset\r\n",
        "imdb_df = h2o.import_file(\"/content/drive/MyDrive/CIT/FYP/ImplementationFiles/IMDB_Dataset.csv\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i7wYL_RvIq5",
        "outputId": "8f0b246a-c2ee-48f9-c476-f71babc97087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# The h2o frame created is a bit weird so rename the columns to the correct names\r\n",
        "imdb_df = imdb_df.rename(columns={'C1':'review', 'C2':'sentiment'})\r\n",
        "# Drop the first row as it has the column names\r\n",
        "imdb_df = imdb_df.drop([0], 0)\r\n",
        "# Take a look\r\n",
        "imdb_df.describe()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rows:49999\n",
            "Cols:2\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>       </th><th>review                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               </th><th>sentiment  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>type   </td><td>string                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               </td><td>enum       </td></tr>\n",
              "<tr><td>mins   </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td><td>           </td></tr>\n",
              "<tr><td>mean   </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td><td>           </td></tr>\n",
              "<tr><td>maxs   </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td><td>           </td></tr>\n",
              "<tr><td>sigma  </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td><td>           </td></tr>\n",
              "<tr><td>zeros  </td><td>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </td><td>           </td></tr>\n",
              "<tr><td>missing</td><td>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </td><td>0          </td></tr>\n",
              "<tr><td>0      </td><td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only &quot;has got all the polari&quot; but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams&#x27; diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master&#x27;s of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional &#x27;dream&#x27; techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell&#x27;s murals decorating every surface) are terribly well done.                                                                                                                                                                                                                                                                                                                               </td><td>positive   </td></tr>\n",
              "<tr><td>1      </td><td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I&#x27;d laughed at one of Woody&#x27;s comedies in years (dare I say a decade?). While I&#x27;ve never been impressed with Scarlet Johanson, in this she managed to tone down her &quot;sexy&quot; image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of his career, but it was wittier than &quot;Devil Wears Prada&quot; and more interesting than &quot;Superman&quot; a great comedy to go see with friends.                                                                                                                                                                                                                                                                                                                                                                                                       </td><td>positive   </td></tr>\n",
              "<tr><td>2      </td><td>Basically there&#x27;s a family where a little boy (Jake) thinks there&#x27;s a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you&#x27;re going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td><td>negative   </td></tr>\n",
              "<tr><td>3      </td><td>Petter Mattei&#x27;s &quot;Love in the Time of Money&quot; is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler&#x27;s play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.&lt;br /&gt;&lt;br /&gt;The acting is good under Mr. Mattei&#x27;s direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.&lt;br /&gt;&lt;br /&gt;We wish Mr. Mattei good luck and await anxiously for his next work.</td><td>positive   </td></tr>\n",
              "<tr><td>4      </td><td>Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it&#x27;s not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas&#x27; performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like &quot;dressed-up midgets&quot; than children, but that only makes them more fun to watch. And the mother&#x27;s slow awakening to what&#x27;s happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they&#x27;d all be &quot;up&quot; for this movie.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td><td>positive   </td></tr>\n",
              "<tr><td>5      </td><td>I sure would like to see a resurrection of a up dated Seahunt series with the tech they have today it would bring back the kid excitement in me.I grew up on black and white TV and Seahunt with Gunsmoke were my hero&#x27;s every week.You have my vote for a comeback of a new sea hunt.We need a change of pace in TV and this would work for a world of under water adventure.Oh by the way thank you for an outlet like this to view many viewpoints about TV and the many movies.So any ole way I believe I&#x27;ve got what I wanna say.Would be nice to read some more plus points about sea hunt.If my rhymes would be 10 lines would you let me submit,or leave me out to be in doubt and have me to quit,If this is so then I must go so lets do it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               </td><td>positive   </td></tr>\n",
              "<tr><td>6      </td><td>This show was an amazing, fresh &amp; innovative idea in the 70&#x27;s when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it&#x27;s continued its decline further to the complete waste of time it is today.&lt;br /&gt;&lt;br /&gt;It&#x27;s truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn&#x27;t still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can&#x27;t believe it&#x27;s still on the air.                                                                                                                                                                                                                                                                                                                                                                                               </td><td>negative   </td></tr>\n",
              "<tr><td>7      </td><td>Encouraged by the positive comments about this film on here I was looking forward to watching this film. Bad mistake. I&#x27;ve seen 950+ films and this is truly one of the worst of them - it&#x27;s awful in almost every way: editing, pacing, storyline, &#x27;acting,&#x27; soundtrack (the film&#x27;s only song - a lame country tune - is played no less than four times). The film looks cheap and nasty and is boring in the extreme. Rarely have I been so happy to see the end credits of a film. &lt;br /&gt;&lt;br /&gt;The only thing that prevents me giving this a 1-score is Harvey Keitel - while this is far from his best performance he at least seems to be making a bit of an effort. One for Keitel obsessives only.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td>negative   </td></tr>\n",
              "<tr><td>8      </td><td>If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.&lt;br /&gt;&lt;br /&gt;Great Camp!!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td><td>positive   </td></tr>\n",
              "<tr><td>9      </td><td>Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines.&lt;br /&gt;&lt;br /&gt;At first it was very odd and pretty funny but as the movie progressed I didn&#x27;t find the jokes or oddness funny anymore.&lt;br /&gt;&lt;br /&gt;Its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually I just lost interest.&lt;br /&gt;&lt;br /&gt;I imagine this film would appeal to a stoner who is currently partaking.&lt;br /&gt;&lt;br /&gt;For something similar but better try &quot;Brother from another planet&quot;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </td><td>negative   </td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWj3Uvi-1gZb"
      },
      "source": [
        "# Create a train, test and validation split\r\n",
        "# This will create a train split of 70% and test and validation split of 15% each\r\n",
        "imdb_train, imdb_test,imdb_valid = imdb_train.split_frame(ratios=[.7, .15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "iSCHYar_6dB3",
        "outputId": "8fe5fc92-2cc5-4705-eca0-a13f182b6533"
      },
      "source": [
        "\r\n",
        "def main():\r\n",
        "  # X_train, y_train, X_test, y_test = prepare_data()\r\n",
        "\r\n",
        "  # print(len(X_train))\r\n",
        "\r\n",
        "  #==========================================\r\n",
        "  # Insert the code for running the libraries in here\r\n",
        "  \r\n",
        "  # This is how it is recommended to set up the inputs for automl\r\n",
        "  y = \"sentiment\"\r\n",
        "  x = imdb_df.columns\r\n",
        "  x.remove(y)\r\n",
        "\r\n",
        "  # This is using 10 max models, so it will only create 10\r\n",
        "  # You can also tell it to note try to use stacked ensemble.\r\n",
        "  # In this initial test stacked ensemble will be removed to keep it simple\r\n",
        "  # though deep learning will be allowed since it is good on text data\r\n",
        "  # You can also set timeboxes for how long models can run\r\n",
        "  # Verbosity sets whetehr it gives out information while running\r\n",
        "  # nfolds is for validation, by default it is set to 5 and will create validation splits\r\n",
        "  # set nfolds to 0 if you have created your own validation split\r\n",
        "  automodel = H2OAutoML(max_models = 10, max_runtime_secs=39600, seed = 1, exclude_algos = [\"StackedEnsemble\"], verbosity=\"info\", nfolds=0)\r\n",
        "  \r\n",
        "  # Train the automl, x sets the training columns, y is the y columns\r\n",
        "  automodel.train(x = x, y = y, training_frame = imdb_train, validation_frame=imdb_valid)\r\n",
        "  # aml = H2OAutoML(max_models=20, seed=1)\r\n",
        "  \r\n",
        "\r\n",
        "  #==========================================\r\n",
        "\r\n",
        "main()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.10\" 2021-01-19; OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04); OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.6/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpbvp5o3k3\n",
            "  JVM stdout: /tmp/tmpbvp5o3k3/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpbvp5o3k3/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>04 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.32.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>17 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_6mmpwa</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.180 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>accepting new members, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O_API_Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.6.9 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         04 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.32.0.4\n",
              "H2O_cluster_version_age:    17 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_6mmpwa\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.180 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         accepting new members, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python_version:             3.6.9 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}