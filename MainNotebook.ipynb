{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TPOT MainNotebook",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1W2EaXPitZCrgFBWxtQNDxSJPPSrAfrO3",
      "authorship_tag": "ABX9TyNF7SXjP+FQbICoSMfrMhcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fa9f586d4a743f681f97b89d446608e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d75876593921436b94f2ba9cd99ac28d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_237a3f322d8542ba969ba738d96c1dae",
              "IPY_MODEL_e95998a4455a494fa0f1207eb632e14b"
            ]
          }
        },
        "d75876593921436b94f2ba9cd99ac28d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "237a3f322d8542ba969ba738d96c1dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ebac0910990a47b5877252742c73d6c9",
            "_dom_classes": [],
            "description": "Optimization Progress: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a5100bdc04943c28bd65841281f3cfe"
          }
        },
        "e95998a4455a494fa0f1207eb632e14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ea0fe15169c4e7287f96aba17a3ff68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 19/? [49:45&lt;00:00, 156.40s/pipeline]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53f82dbb96f242629eafa0152db561c4"
          }
        },
        "ebac0910990a47b5877252742c73d6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a5100bdc04943c28bd65841281f3cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ea0fe15169c4e7287f96aba17a3ff68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53f82dbb96f242629eafa0152db561c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22846077e7df40ccaa7c0079e29ec190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7cdb3135b8924eb3b7d2ff3a9960a1dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d1ade10976324092b6c2e8259dd43f56",
              "IPY_MODEL_6cdd6d0658e74e7a9b9ba40a0daa396b"
            ]
          }
        },
        "7cdb3135b8924eb3b7d2ff3a9960a1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1ade10976324092b6c2e8259dd43f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f9448127f06c4ff6a7613b5b21cba403",
            "_dom_classes": [],
            "description": "Optimization Progress: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1c1f337193d414f8a456a57bccb216b"
          }
        },
        "6cdd6d0658e74e7a9b9ba40a0daa396b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ac8233a3f0645ea8385a4f216b198c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 19/? [51:52&lt;00:00, 166.44s/pipeline]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3335317ae914b36b2346d6b59aec1aa"
          }
        },
        "f9448127f06c4ff6a7613b5b21cba403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1c1f337193d414f8a456a57bccb216b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ac8233a3f0645ea8385a4f216b198c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3335317ae914b36b2346d6b59aec1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CianOSull/AutoML_With_SA_FYP_2021/blob/TPOT/MainNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_zrt8fk5AJt"
      },
      "source": [
        "# Generic Notebook for running all the libraries\r\n",
        "\r\n",
        "How this notebook works is that it contains the code\r\n",
        "for loading and cleaning the dataset.\r\n",
        "\r\n",
        "Then there is multiple branches created on the\r\n",
        "Github that include the code for running each library.\r\n",
        "\r\n",
        "E.g. MLBox branch has the code for running MLBox."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idZkm3ZBASxO"
      },
      "source": [
        "# CURRENT BRANCH: TPOT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJiawHdY2egK"
      },
      "source": [
        "# Install TPOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wFpyMaK6tMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c93d616-d432-4659-ff9b-86e7dd904c05"
      },
      "source": [
        "# Insert any install comamnds in this cell\r\n",
        "!pip install deap update_checker tqdm stopit xgboost\r\n",
        "!pip install tpot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: update_checker in /usr/local/lib/python3.7/dist-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: stopit in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update_checker) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update_checker) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update_checker) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update_checker) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update_checker) (2.10)\n",
            "Requirement already satisfied: tpot in /usr/local/lib/python3.7/dist-packages (0.11.7)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.1.5)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.3.3)\n",
            "Requirement already satisfied: deap>=1.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tpot) (0.22.2.post1)\n",
            "Requirement already satisfied: stopit>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.1.2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.4.1)\n",
            "Requirement already satisfied: update-checker>=0.16 in /usr/local/lib/python3.7/dist-packages (from tpot) (0.18.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.16->tpot) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TNIZJ6c5hcF"
      },
      "source": [
        "# Preprocessing Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njEYGcZQ42t-"
      },
      "source": [
        "# Import the necessary modules for cleaning\r\n",
        "import math\r\n",
        "import time \r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.tokenize import word_tokenize \r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sPOCEGS5Xgn"
      },
      "source": [
        "# Create the set of stopwords for cleaning text\r\n",
        "stopwords = set(w.rstrip() for w in open('/content/drive/MyDrive/CIT/FYP/ImplementationFiles/stopwords.txt'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93NNPX-A5srS",
        "outputId": "95a99a34-9ab9-4a4d-eda3-dcea659cefb6"
      },
      "source": [
        "# Download the necessary parts for the NLTK module\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4ptneBc5tAN"
      },
      "source": [
        "# This funciton handles celaning text\r\n",
        "def clean_text(text):\r\n",
        "    # Create the lemmatizer\r\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\r\n",
        "    \r\n",
        "    # Get rid of non alpha characters except \"'\" as it is needed for the lemment\r\n",
        "    text = \"\".join(c for c in text if c.isalnum() or c == \" \" or \"'\")\r\n",
        "    \r\n",
        "    # Get rid of capitals\r\n",
        "    text = text.lower()\r\n",
        "    \r\n",
        "    # Tokenize the words    \r\n",
        "    # Create tokens of each word\r\n",
        "    token_text = word_tokenize(text)\r\n",
        "    \r\n",
        "    # Get rid of any piece of text that isn't over 2 characters\r\n",
        "    token_text = [t for t in token_text if len(t) > 2] \r\n",
        "    \r\n",
        "    # Put words in base form by doing lemmatization\r\n",
        "    token_text = [wordnet_lemmatizer.lemmatize(t) for t in token_text]\r\n",
        "\r\n",
        "    # Remove stopwords\r\n",
        "    token_text = [t for t in token_text if t not in stopwords]\r\n",
        "    \r\n",
        "    # Return the tokens\r\n",
        "    return token_text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu5dFDM75tjR"
      },
      "source": [
        "# This function will get the term frequencies for word in the review\r\n",
        "# TF = Term I frequency in document/total words in document\r\n",
        "def calc_tf(term_count, review_corpus):\r\n",
        "    # A dictionary of all the term frequencies found\r\n",
        "    tf_freq = dict.fromkeys(term_count.keys(), 0)   \r\n",
        "    \r\n",
        "    # Review corpus is a tokenized list so the total words iteh length\r\n",
        "    total_words = len(review_corpus)\r\n",
        "    \r\n",
        "    # Calculate the term frequency for each word\r\n",
        "    for word, count in term_count.items():\r\n",
        "        tf_freq[word] = count/total_words\r\n",
        "        \r\n",
        "    return tf_freq"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i64Bq0rH5uN0"
      },
      "source": [
        "# This calcualtes the idf\r\n",
        "# IDF = log(2)*(Total number of Documents/documents frequency or documents with term)\r\n",
        "def calc_idf(unique_terms, list_doc_terms):   \r\n",
        "    # A dicitonary of all the inverse document frequencies\r\n",
        "    idf = dict.fromkeys(unique_terms, 0)\r\n",
        "    \r\n",
        "    # Basically list_doc_terms has all the documents with the term count for each word\r\n",
        "    # You go through each document count the terms where they occured\r\n",
        "    for doc_terms in list_doc_terms:  \r\n",
        "        # This for loop is counting the amount of document a word was in\r\n",
        "        for word, value in doc_terms.items():\r\n",
        "            if 0 < value:\r\n",
        "                idf[word] += 1\r\n",
        "        \r\n",
        "    # Now we calculate idf\r\n",
        "    for word, value in idf.items():\r\n",
        "        idf[word] = math.log10(10 / float(value))\r\n",
        "    \r\n",
        "    return idf"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XTmL87F5uaU"
      },
      "source": [
        "# Modified this function to return a list as dictionaries arn't needed anymore\r\n",
        "def calc_tf_idf(tf, idf, n_terms):\r\n",
        "    # Create an array that is of length of the number of unique terms\r\n",
        "    tf_idf_array = np.zeros(n_terms)\r\n",
        "    \r\n",
        "    for index, (word, value) in enumerate(tf.items()):\r\n",
        "        # Add the tfidf to the array\r\n",
        "        tf_idf_array[index] = value*idf[word]\r\n",
        "    \r\n",
        "    return tf_idf_array"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzOme9px5uks"
      },
      "source": [
        "def process_text(text_data):\r\n",
        "    # A list of all the cleaned reviews\r\n",
        "    doc_list = []\r\n",
        "    \r\n",
        "    # List of all the unique terms\r\n",
        "    unique_terms = []\r\n",
        "    \r\n",
        "    # A list of all the term frequencies\r\n",
        "    tf_list = []\r\n",
        "    \r\n",
        "    for review in text_data:\r\n",
        "        # First clean the review\r\n",
        "        clean_review = clean_text(review)\r\n",
        "        \r\n",
        "        # Keeps track of the term counts for each word\r\n",
        "        count_dict = {}\r\n",
        "        \r\n",
        "        # Now lets find the total count for each word\r\n",
        "        for token in clean_review:\r\n",
        "            if token not in count_dict:\r\n",
        "                count_dict[token] = 1\r\n",
        "            else:\r\n",
        "                count_dict[token] += 1\r\n",
        "        \r\n",
        "        # Caclulate the term frequencies for each document\r\n",
        "        tf_list.append(calc_tf(count_dict, clean_review))\r\n",
        "        \r\n",
        "        # Then add the dictionary of counts for each document to the list\r\n",
        "        doc_list.append(count_dict)\r\n",
        "        \r\n",
        "        # Then add the new unique terms\r\n",
        "        unique_terms = set(unique_terms).union(set(clean_review))\r\n",
        "    \r\n",
        "    # Calculate the inverse document frequency value\r\n",
        "    idf = calc_idf(unique_terms, doc_list)\r\n",
        "    \r\n",
        "    # This array will contain the tfidf values for each term in each review\r\n",
        "    tfidf_values = np.zeros((len(tf_list), len(unique_terms)))\r\n",
        "    \r\n",
        "    # Now we can get the TFIDF for each document\r\n",
        "    for index, term_freq in enumerate(tf_list):\r\n",
        "        # This will return an array of the tfidf values calculated.\r\n",
        "        # The length of the unique terms list is passed in so that the \r\n",
        "        # Array that is returned matches the tfidf array\r\n",
        "        tf_idf_array = calc_tf_idf(term_freq, idf, len(unique_terms))\r\n",
        "        # Add this to the overall tfidf values calculated\r\n",
        "        tfidf_values[index,:] = tf_idf_array\r\n",
        "    \r\n",
        "    return tfidf_values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUz1Vq_D6Ett"
      },
      "source": [
        "# Prepare the data\r\n",
        "def prepare_data():\r\n",
        "    print(\"=\"*50)\r\n",
        "\r\n",
        "    # Load the dataset\r\n",
        "    # imdb_df = pd.read_csv(\"IMDB Dataset.csv\")\r\n",
        "    imdb_df = pd.read_csv(\"/content/drive/MyDrive/CIT/FYP/ImplementationFiles/IMDB_Dataset.csv\")\r\n",
        "    print(\"Dataset loaded\")\r\n",
        "    print(\"=\"*50)\r\n",
        "\r\n",
        "    \r\n",
        "     # Change each positive and negative value to 1 and 0 respectively    \r\n",
        "    imdb_df['sentiment'] = imdb_df['sentiment'].map({'negative' : 0, 'positive' : 1})\r\n",
        "    \r\n",
        "    # For testing, a much smaller dataset is going to be used\r\n",
        "    # imdb_df = imdb_df.head(25000)\r\n",
        "\r\n",
        "    # Group all the negative reviews and get the first 2500\r\n",
        "    imdb_df_neg = (imdb_df[imdb_df['sentiment'] == 0])[0:2500]\r\n",
        "    # Group all the positive and get the first 2500\r\n",
        "    imdb_df_pos = imdb_df[imdb_df['sentiment'] == 1][0:2500]\r\n",
        "    \r\n",
        "    # Combine the two split positives and negatives into one dataframe\r\n",
        "    imdb_df = pd.concat([imdb_df_neg, imdb_df_pos]) \r\n",
        "    # print(test_df)\r\n",
        "    \r\n",
        "    # .values on a column of a dataframe returns a numpy array\r\n",
        "    # This is a numpy array of all the reviews\r\n",
        "    # initial_reviews = imdb_df['review'].values\r\n",
        "    initial_reviews = imdb_df['review'].values\r\n",
        "    \r\n",
        "    # This is a numpy array of all the positive and negativelabels\r\n",
        "    # labels = imdb_df['sentiment'].values\r\n",
        "    labels = imdb_df['sentiment'].values\r\n",
        "    \r\n",
        "    print(\"Creating Feature Vector\")\r\n",
        "    print(\"=\"*50)\r\n",
        "    start = time.time()\r\n",
        "    # Process the text data and create teh feature vector\r\n",
        "    feature_vector = process_text(initial_reviews)\r\n",
        "    end = time.time()\r\n",
        "    print(\"Feature Vector Created\")\r\n",
        "    print(f\"Execution time is {end - start} secs\")\r\n",
        "    print(\"=\"*50)\r\n",
        "    \r\n",
        "    # Shuffle the labesl and feature vector using sklearn shuffle\r\n",
        "    feature_vector, labels = shuffle(feature_vector, labels)\r\n",
        "    \r\n",
        "    # Creating train and test data\r\n",
        "    # The splits will be 80:20 \r\n",
        "    no_samples = 0.8\r\n",
        "    \r\n",
        "    # This gets the percentage of indexes from feature vector and uses those for training\r\n",
        "    X_train = feature_vector[0:int(no_samples*len(feature_vector))]\r\n",
        "    y_train = labels[0:int(no_samples*len(labels))]\r\n",
        "    \r\n",
        "    # Go from the index that was used for training to the final\r\n",
        "    X_test = feature_vector[int(no_samples*len(feature_vector)):len(feature_vector)]\r\n",
        "    y_test = labels[int(no_samples*len(labels)):len(labels)]\r\n",
        "\r\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew8tq1lj6v1L"
      },
      "source": [
        "# Run the automl\r\n",
        "\r\n",
        "http://epistasislab.github.io/tpot/using/#tpot-with-code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDiJemo62wgW",
        "outputId": "e1dc8286-e183-4963-8bd8-711e10c838e2"
      },
      "source": [
        "X_train, y_train, X_test, y_test = prepare_data()\r\n",
        "print(len(X_train))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Dataset loaded\n",
            "==================================================\n",
            "Creating Feature Vector\n",
            "==================================================\n",
            "Feature Vector Created\n",
            "Execution time is 35.5163037776947 secs\n",
            "==================================================\n",
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77LRmcIo22Rl",
        "outputId": "b61223d7-3499-41ff-8cea-caff32b063d0"
      },
      "source": [
        "# Insert the code for running the libraries in here\r\n",
        "from tpot import TPOTClassifier\r\n",
        "\r\n",
        "pipeline_optimizer = TPOTClassifier()\r\n",
        "\r\n",
        "# This is the example classifier used\r\n",
        "pipeline_optimizer = TPOTClassifier(generations=1, population_size=5, cv=5,\r\n",
        "                                  random_state=42, verbosity=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "1fa9f586d4a743f681f97b89d446608e",
            "d75876593921436b94f2ba9cd99ac28d",
            "237a3f322d8542ba969ba738d96c1dae",
            "e95998a4455a494fa0f1207eb632e14b",
            "ebac0910990a47b5877252742c73d6c9",
            "8a5100bdc04943c28bd65841281f3cfe",
            "3ea0fe15169c4e7287f96aba17a3ff68",
            "53f82dbb96f242629eafa0152db561c4"
          ]
        },
        "id": "hV2uIzd_2_AS",
        "outputId": "28bd5f20-af4f-4196-eaf2-bd5ec4a0f580"
      },
      "source": [
        "print(\"Creating Model\")\r\n",
        "print(\"=\"*50)\r\n",
        "start = time.time()\r\n",
        "try:\r\n",
        "  pipeline_optimizer.fit(X_train, y_train)\r\n",
        "except Exception as e:\r\n",
        "  print(e)\r\n",
        "end = time.time()\r\n",
        "print(\"Model Created\")\r\n",
        "print(f\"Execution time is {end - start} secs\")\r\n",
        "print(\"=\"*50)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Model\n",
            "==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fa9f586d4a743f681f97b89d446608e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=10.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Generation 1 - Current best internal CV score: 0.503\n",
            "\r\n",
            "Best pipeline: GaussianNB(input_matrix)\n",
            "Model Created\n",
            "Execution time is 3001.167653799057 secs\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzsUVMCg3Dgd",
        "outputId": "7f48e94f-5f02-4a64-afe5-acde10b40be1"
      },
      "source": [
        "print(\"Evaluating Model\")\r\n",
        "print(\"=\"*50)\r\n",
        "start = time.time()\r\n",
        "print(pipeline_optimizer.score(X_test, y_test))\r\n",
        "end = time.time()\r\n",
        "print(\"Evaluating done\")\r\n",
        "print(f\"Execution time is {end - start} secs\")\r\n",
        "print(\"=\"*50)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Model\n",
            "==================================================\n",
            "0.504\n",
            "Evaluating done\n",
            "Execution time is 1.1137540340423584 secs\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoxoTKWr3E5s",
        "outputId": "b060d3b4-ecd3-4351-8ac0-ee430b36b206"
      },
      "source": [
        "# Naming convention is tpot_time_pop\r\n",
        "print(\"Exporting Model\")\r\n",
        "print(\"=\"*50)\r\n",
        "# Format is tpot_generations_populatiopn_datasize\r\n",
        "pipeline_optimizer.export('/content/drive/MyDrive/CIT/FYP/ImplementationFiles/ExportedModels/TPOT/tpot_1_5_5000.py')\r\n",
        "print(\"Model Exported\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exporting Model\n",
            "==================================================\n",
            "Model Exported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564,
          "referenced_widgets": [
            "22846077e7df40ccaa7c0079e29ec190",
            "7cdb3135b8924eb3b7d2ff3a9960a1dd",
            "d1ade10976324092b6c2e8259dd43f56",
            "6cdd6d0658e74e7a9b9ba40a0daa396b",
            "f9448127f06c4ff6a7613b5b21cba403",
            "c1c1f337193d414f8a456a57bccb216b",
            "4ac8233a3f0645ea8385a4f216b198c7",
            "b3335317ae914b36b2346d6b59aec1aa"
          ]
        },
        "id": "iSCHYar_6dB3",
        "outputId": "00d538c7-79e3-46ca-a59e-db6616806d8d"
      },
      "source": [
        "\r\n",
        "def main():\r\n",
        "  X_train, y_train, X_test, y_test = prepare_data()\r\n",
        "\r\n",
        "  print(len(X_train))\r\n",
        "\r\n",
        "  #==========================================\r\n",
        "  # Insert the code for running the libraries in here\r\n",
        "  from tpot import TPOTClassifier\r\n",
        "\r\n",
        "  pipeline_optimizer = TPOTClassifier()\r\n",
        "\r\n",
        "  # population size is how much data it brings to each model, keep it low for\r\n",
        "  # possible ram issues\r\n",
        "  # pipeline_optimizer = TPOTClassifier(max_time_mins=660, population_size=10, cv=5,\r\n",
        "  #                                   random_state=42, verbosity=2)\r\n",
        "\r\n",
        "  # This is the example classifier used\r\n",
        "  pipeline_optimizer = TPOTClassifier(generations=1, population_size=5, cv=5,\r\n",
        "                                    random_state=42, verbosity=2)\r\n",
        "  \r\n",
        "  print(\"Creating Model\")\r\n",
        "  print(\"=\"*50)\r\n",
        "  start = time.time()\r\n",
        "  try:\r\n",
        "    pipeline_optimizer.fit(X_train, y_train)\r\n",
        "  except Exception as e:\r\n",
        "    print(e)\r\n",
        "  end = time.time()\r\n",
        "  print(\"Model Created\")\r\n",
        "  print(f\"Execution time is {end - start} secs\")\r\n",
        "  print(\"=\"*50)\r\n",
        "\r\n",
        "  print(\"Evaluating Model\")\r\n",
        "  print(\"=\"*50)\r\n",
        "  start = time.time()\r\n",
        "  print(pipeline_optimizer.score(X_test, y_test))\r\n",
        "  end = time.time()\r\n",
        "  print(\"Evaluating done\")\r\n",
        "  print(f\"Execution time is {end - start} secs\")\r\n",
        "  print(\"=\"*50)\r\n",
        "\r\n",
        "  # Naming convention is tpot_time_pop\r\n",
        "  print(\"Exporting Model\")\r\n",
        "  print(\"=\"*50)\r\n",
        "  # Format is tpot_generations_populatiopn_datasize\r\n",
        "  pipeline_optimizer.export('/content/drive/MyDrive/CIT/FYP/ImplementationFiles/ExportedModels/TPOT/tpot_1_5_5000.py')\r\n",
        "  print(\"Model Exported\")\r\n",
        "\r\n",
        "  #==========================================\r\n",
        "\r\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Dataset loaded\n",
            "==================================================\n",
            "Creating Feature Vector\n",
            "==================================================\n",
            "Feature Vector Created\n",
            "Execution time is 29.461904764175415 secs\n",
            "==================================================\n",
            "4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating Model\n",
            "==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22846077e7df40ccaa7c0079e29ec190",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=10.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Generation 1 - Current best internal CV score: 0.5035000000000001\n",
            "\r\n",
            "Best pipeline: GaussianNB(input_matrix)\n",
            "Model Created\n",
            "Execution time is 3125.228134870529 secs\n",
            "==================================================\n",
            "Evaluating Model\n",
            "==================================================\n",
            "0.48\n",
            "Evaluating done\n",
            "Execution time is 1.3757824897766113 secs\n",
            "==================================================\n",
            "Exporting Model\n",
            "==================================================\n",
            "Model Exported\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}